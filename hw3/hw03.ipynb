{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat 257 Homework 3\n",
    "\n",
    "**Due May 14 @ 11:59PM**\n",
    "\n",
    "**Elvis Cui** elviscuihan@g.ucla.edu\n",
    "\n",
    "*PhD Student at Department of Biostatistics, UCLA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.6.0\n",
      "Commit f9720dc2eb (2021-03-24 12:55 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.6.0)\n",
      "  CPU: Apple M1\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, westmere)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Big $n$ linear regression\n",
    "\n",
    "People often think linear regression on a dataset with millions of observations is a big data problem. Now we learnt various methods for solving linear regression and should realize that, with right choice of algorithm, it is a problem that can be handled by any moderate computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Download data (10pts)\n",
    "\n",
    "Download the flight data from <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HG7NV7>. **Do not put data files in Git.** You will lose points if you do. For grading purpose (reproducibility), we will assume that data files are in a subfolder `flights`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CodecBzip2, CSV, DataFrames, Distributions, LinearAlgebra, \n",
    "Serialization, StatsModels, SweepOperator\n",
    "ENV[\"COLUMNS\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3095696\n",
      "-rw-rw-r--@ 1 elviscui  staff   12652442 May  3 03:08 1987.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   49499025 May  3 03:08 1988.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   49202298 May  3 03:09 1989.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   52041322 May  3 03:09 1990.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   49877448 May  3 03:10 1991.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   50040946 May  3 03:10 1992.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   50111774 May  3 03:10 1993.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   51123887 May  3 03:11 1994.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   74881752 May  3 03:11 1995.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   75887707 May  3 03:11 1996.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   76705687 May  3 03:12 1997.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   76683506 May  3 03:12 1998.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   79449438 May  3 03:12 1999.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   82537924 May  3 03:12 2000.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   83478700 May  3 03:13 2001.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   75907218 May  3 03:13 2002.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   95326801 May  3 03:13 2003.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff  110825331 May  3 03:14 2004.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff  112450321 May  3 03:14 2005.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff  115019195 May  3 03:15 2006.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff  121249243 May  3 03:15 2007.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff   39277452 May  3 03:16 2008.csv.bz2\n",
      "-rw-rw-r--@ 1 elviscui  staff     244438 May  3 03:16 airports.csv\n",
      "-rw-rw-r--@ 1 elviscui  staff      43758 May  3 03:16 carriers.csv\n",
      "-rw-rw-r--@ 1 elviscui  staff     428796 May  3 03:16 plane-data.csv\n",
      "-rw-rw-r--@ 1 elviscui  staff       1091 May  3 03:16 variable-descriptions.csv\n"
     ]
    }
   ],
   "source": [
    ";ls -l flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many data points are in each year.\n",
    "\n",
    "**I personally would suggest check the \"effective\" observations in the model fitting step, since we are going to drop a lot of obs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987.csv.bz2, 1311827\n",
      "1988.csv.bz2, 5202097\n",
      "1989.csv.bz2, 5041201\n",
      "1990.csv.bz2, 5270894\n",
      "1991.csv.bz2, 5076926\n",
      "1992.csv.bz2, 5092158\n",
      "1993.csv.bz2, 5070502\n",
      "1994.csv.bz2, 5180049\n",
      "1995.csv.bz2, 5327436\n",
      "1996.csv.bz2, 5351984\n",
      "1997.csv.bz2, 5411844\n",
      "1998.csv.bz2, 5384722\n",
      "1999.csv.bz2, 5527885\n",
      "2000.csv.bz2, 5683048\n",
      "2001.csv.bz2, 5967781\n",
      "2002.csv.bz2, 5271360\n",
      "2003.csv.bz2, 6488541\n",
      "2004.csv.bz2, 7129271\n",
      "2005.csv.bz2, 7140597\n",
      "2006.csv.bz2, 7141923\n",
      "2007.csv.bz2, 7453216\n",
      "2008.csv.bz2, 2389218\n"
     ]
    }
   ],
   "source": [
    "files = readdir(\"flights/\")[1:22]\n",
    "\n",
    "for file in files\n",
    "    open(string(\"flights/\", file), \"r\") do io\n",
    "        num = countlines(Bzip2DecompressorStream(io))\n",
    "        print(file, \", \", num, \"\\n\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 (10 pts) Problem size\n",
    "\n",
    "We are interested in how the arrival delay of a flight, `ArrDelay`, depends on the distance traveled (`Distance`), departure delay (`DepDelay`), weekday (`DayOfWeek`), and airline (`UniqueCarrier`). \n",
    "\n",
    "We want to fit a linear regression `ArrDelay ~ 1 + Distance + DepDelay + DayOfWeek + UniqueCarrier` using data from 1987-2008. Treat `DayOfWeek` as a factor with 6 levels. We use the dummy coding with `1` (Monday) as the base level. Treat `UniqueCarrier` as a factor with 8 levels: \"AA\", \"AS\", \"CO\", \"DL\", \"NW\", \"UA\", \"US\", and \"WN\". We use the dummy coding with \"AA\" as the base level.\n",
    "\n",
    "Will the design matrix $\\mathbf{X}$ (in double precision) fit into the memory of your computer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- My computer memory: 16 GB [MacBook Pro (13-inch, M1, 2020)].\n",
    "- Next I calculate the size of all files in **flights**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of all files is: 1.58 GB."
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "\n",
    "for file in files\n",
    "    total_size += filesize(\"flights/\" * file)\n",
    "end\n",
    "\n",
    "print(\"The total size of all files is: \", round(total_size / (1_000_000_000), digits=2), \" GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conclusion:** \n",
    "Since DoublePrecision costs 64 bits, or 8 Bytes, so the total storage required should be around\n",
    "\n",
    "    $$1.58\\times 8\\approx 12.8GB<16GB$$\n",
    "    \n",
    "$$\\text{It seems that the design matrix $X$ CAN fit into the memory of my computer.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 (30 pts) Choose algorithm\n",
    "\n",
    "Assume your computer has limited memory, say only 1GB. Review the [Summary of Linear Regression](https://ucla-biostat-257-2021spring.github.io/slides/15-linreg/linreg.html) and choose one method in the table to solve the linear regression.\n",
    "\n",
    "Report the estimated regression coefficients $\\widehat \\beta$, estimated variance $\\widehat \\sigma^2 = \\sum_i (y_i - \\widehat y_i)^2 / (n - p)$, and standard errors of $\\widehat \\beta$.\n",
    "\n",
    "Hint: It took my laptop about 10-11 minutes to import data and fit linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparation\n",
    "\n",
    "airlines = [\"AA\", \"AS\", \"CO\", \"DL\", \"NW\", \"UA\", \"US\", \"WN\"]\n",
    "\n",
    "Xty = zeros(16)\n",
    "XtX = zeros(16, 16)\n",
    "\n",
    "obs_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1987 costs: 10.220058 seconds (27.76 M allocations: 1.600 GiB, 3.11% gc time, 26.35% compilation time)\n",
      "Year 1988 costs: 10.950856 seconds (5.20 M allocations: 989.537 MiB, 1.46% gc time)\n",
      "Year 1989 costs: 10.863127 seconds (5.04 M allocations: 968.166 MiB, 2.64% gc time)\n",
      "Year 1990 costs: 11.183744 seconds (5.27 M allocations: 998.383 MiB, 0.43% gc time)\n",
      "Year 1991 costs: 10.731154 seconds (5.08 M allocations: 975.487 MiB, 2.87% gc time)\n",
      "Year 1992 costs: 10.654390 seconds (5.09 M allocations: 988.190 MiB)\n",
      "Year 1993 costs: 11.136424 seconds (5.07 M allocations: 979.252 MiB, 3.46% gc time)\n",
      "Year 1994 costs: 11.018311 seconds (5.18 M allocations: 991.988 MiB, 3.14% gc time)\n",
      "Year 1995 costs: 12.478349 seconds (5.33 M allocations: 1005.601 MiB, 0.51% gc time)\n",
      "Year 1996 costs: 12.791197 seconds (5.39 M allocations: 1005.090 MiB, 2.72% gc time, 0.37% compilation time)\n",
      "Year 1997 costs: 13.044791 seconds (5.41 M allocations: 1.495 GiB, 0.53% gc time)\n",
      "Year 1998 costs: 13.342578 seconds (5.39 M allocations: 1.497 GiB, 2.05% gc time)\n",
      "Year 1999 costs: 13.590399 seconds (5.53 M allocations: 1.501 GiB, 2.01% gc time)\n",
      "Year 2000 costs: 13.718896 seconds (5.68 M allocations: 1.512 GiB, 0.79% gc time)\n",
      "Year 2001 costs: 14.356708 seconds (5.97 M allocations: 1.540 GiB, 0.71% gc time)\n",
      "Year 2002 costs: 12.826995 seconds (5.27 M allocations: 1000.824 MiB, 2.03% gc time)\n",
      "Year 2003 costs: 15.948438 seconds (6.49 M allocations: 1.072 GiB, 2.63% gc time)\n",
      "Year 2004 costs: 17.411532 seconds (7.13 M allocations: 1.650 GiB, 0.54% gc time)\n",
      "Year 2005 costs: 17.947195 seconds (7.14 M allocations: 1.641 GiB, 1.90% gc time)\n",
      "Year 2006 costs: 18.150762 seconds (7.14 M allocations: 1.643 GiB, 1.71% gc time)\n",
      "Year 2007 costs: 19.108615 seconds (7.45 M allocations: 1.683 GiB, 1.81% gc time)\n",
      "Year 2008 costs:  6.070156 seconds (2.39 M allocations: 481.407 MiB)\n",
      "Total count of obs is: 91545745"
     ]
    }
   ],
   "source": [
    "for year in 1987:2008\n",
    "    \n",
    "    print(\"Year \" * string(year) * \" costs:\")\n",
    "    \n",
    "    # load data from different years into DataFrame\n",
    "    @time df = open(\"flights/\" * string(year) * \".csv.bz2\", \"r\") do io\n",
    "        CSV.File(\n",
    "            Bzip2DecompressorStream(io), \n",
    "            select = [\"DayOfWeek\", \"UniqueCarrier\", \"ArrDelay\", \n",
    "                \"DepDelay\", \"Distance\"],\n",
    "            types = Dict(\n",
    "                \"DayOfWeek\" => UInt8,\n",
    "                \"UniqueCarrier\" => String, \n",
    "                \"ArrDelay\" => Float64, \n",
    "                \"DepDelay\" => Float64, \n",
    "                \"Distance\" => UInt16\n",
    "                ),\n",
    "            missingstring = \"NA\"\n",
    "            ) |> DataFrame\n",
    "    end \n",
    "\n",
    "    filter!(row -> row[:UniqueCarrier] ∈ airlines, df)\n",
    "    dropmissing!(df)\n",
    "\n",
    "    # model frame for the year\n",
    "    mf = ModelFrame(\n",
    "        @formula(ArrDelay ~ 1 + DayOfWeek + Distance + DepDelay + UniqueCarrier), \n",
    "        df,\n",
    "        contrasts = Dict(\n",
    "            :DayOfWeek => StatsModels.DummyCoding(base = 1, levels = UInt8.(1:7)),\n",
    "            :UniqueCarrier => StatsModels.DummyCoding(\n",
    "                base = \"AA\", \n",
    "                levels = [\"AA\", \"AS\", \"CO\", \"DL\", \"NW\", \"UA\", \"US\", \"WN\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # generate the covariate matrix X for the year\n",
    "    X = modelmatrix(mf)\n",
    "\n",
    "    # generate the response vector Y for the year\n",
    "    y = df[!, :ArrDelay]\n",
    "\n",
    "    Xty += X'y\n",
    "    XtX += X'X\n",
    "    obs_count += length(y)\n",
    "    \n",
    "end\n",
    "\n",
    "print(\"Total count of obs is: \", obs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The estimated vector is**:\n",
    "\n",
    "\\begin{align}\n",
    "\\widehat{\\beta}^T=[\\beta_0, \\beta_\\text{Tue}, \\beta_\\text{Wed}, \\beta_\\text{Thr}, \\beta_\\text{Fri}, \\beta_\\text{Sat}, \\beta_\\text{Sun}, \\beta_{\\text{Dist}}, \\beta_{DepDelay}, \\beta_{AS}, \\cdots,\\beta_{WN}]\n",
    "\\end{align}\n",
    "\n",
    "where $\\beta_0$ is the intercept term for $\\text{AA}$ and $\\text{Monday}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU decomposition solution\n",
    "\n",
    "- $2p^3+2p^2-p$ or $O(p^3)$ flops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(XtX) * Xty;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky decomposition solution\n",
    "- Approximately $\\frac{p^3}{3}+2p^2$ flops, or $O(p^3)$ flops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholesky(XtX) \\ Xty;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep operator solution\n",
    "- This one is easy to calculate:\n",
    "    nothing but $p^3$ flops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SweepOperator\n",
    "\n",
    "hi = [XtX Xty; Xty' 1]\n",
    "sweep!(hi, 1:16)[1:16, end];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put them together**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>beta</th><th>LU</th><th>Cholesky</th><th>Sweep</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>16 rows × 4 columns</p><tr><th>1</th><td>beta0</td><td>0.83561</td><td>0.83561</td><td>0.83561</td></tr><tr><th>2</th><td>Tue</td><td>0.259139</td><td>0.259139</td><td>0.259139</td></tr><tr><th>3</th><td>Wed</td><td>0.668682</td><td>0.668682</td><td>0.668682</td></tr><tr><th>4</th><td>Thr</td><td>1.01573</td><td>1.01573</td><td>1.01573</td></tr><tr><th>5</th><td>Fri</td><td>0.812092</td><td>0.812092</td><td>0.812092</td></tr><tr><th>6</th><td>Sat</td><td>-1.6118</td><td>-1.6118</td><td>-1.6118</td></tr><tr><th>7</th><td>Sun</td><td>-0.704679</td><td>-0.704679</td><td>-0.704679</td></tr><tr><th>8</th><td>Dist</td><td>-0.00140991</td><td>-0.00140991</td><td>-0.00140991</td></tr><tr><th>9</th><td>DepDelay</td><td>0.924935</td><td>0.924935</td><td>0.924935</td></tr><tr><th>10</th><td>AS</td><td>1.03988</td><td>1.03988</td><td>1.03988</td></tr><tr><th>11</th><td>CO</td><td>0.25794</td><td>0.25794</td><td>0.25794</td></tr><tr><th>12</th><td>DL</td><td>0.662151</td><td>0.662151</td><td>0.662151</td></tr><tr><th>13</th><td>NW</td><td>0.0340912</td><td>0.0340912</td><td>0.0340912</td></tr><tr><th>14</th><td>UA</td><td>0.0402917</td><td>0.0402917</td><td>0.0402917</td></tr><tr><th>15</th><td>US</td><td>-0.452353</td><td>-0.452353</td><td>-0.452353</td></tr><tr><th>16</th><td>WN</td><td>-2.976</td><td>-2.976</td><td>-2.976</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& beta & LU & Cholesky & Sweep\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & beta0 & 0.83561 & 0.83561 & 0.83561 \\\\\n",
       "\t2 & Tue & 0.259139 & 0.259139 & 0.259139 \\\\\n",
       "\t3 & Wed & 0.668682 & 0.668682 & 0.668682 \\\\\n",
       "\t4 & Thr & 1.01573 & 1.01573 & 1.01573 \\\\\n",
       "\t5 & Fri & 0.812092 & 0.812092 & 0.812092 \\\\\n",
       "\t6 & Sat & -1.6118 & -1.6118 & -1.6118 \\\\\n",
       "\t7 & Sun & -0.704679 & -0.704679 & -0.704679 \\\\\n",
       "\t8 & Dist & -0.00140991 & -0.00140991 & -0.00140991 \\\\\n",
       "\t9 & DepDelay & 0.924935 & 0.924935 & 0.924935 \\\\\n",
       "\t10 & AS & 1.03988 & 1.03988 & 1.03988 \\\\\n",
       "\t11 & CO & 0.25794 & 0.25794 & 0.25794 \\\\\n",
       "\t12 & DL & 0.662151 & 0.662151 & 0.662151 \\\\\n",
       "\t13 & NW & 0.0340912 & 0.0340912 & 0.0340912 \\\\\n",
       "\t14 & UA & 0.0402917 & 0.0402917 & 0.0402917 \\\\\n",
       "\t15 & US & -0.452353 & -0.452353 & -0.452353 \\\\\n",
       "\t16 & WN & -2.976 & -2.976 & -2.976 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m16×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m beta     \u001b[0m\u001b[1m LU          \u001b[0m\u001b[1m Cholesky    \u001b[0m\u001b[1m Sweep       \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────\n",
       "   1 │ beta0      0.83561      0.83561      0.83561\n",
       "   2 │ Tue        0.259139     0.259139     0.259139\n",
       "   3 │ Wed        0.668682     0.668682     0.668682\n",
       "   4 │ Thr        1.01573      1.01573      1.01573\n",
       "   5 │ Fri        0.812092     0.812092     0.812092\n",
       "   6 │ Sat       -1.6118      -1.6118      -1.6118\n",
       "   7 │ Sun       -0.704679    -0.704679    -0.704679\n",
       "   8 │ Dist      -0.00140991  -0.00140991  -0.00140991\n",
       "   9 │ DepDelay   0.924935     0.924935     0.924935\n",
       "  10 │ AS         1.03988      1.03988      1.03988\n",
       "  11 │ CO         0.25794      0.25794      0.25794\n",
       "  12 │ DL         0.662151     0.662151     0.662151\n",
       "  13 │ NW         0.0340912    0.0340912    0.0340912\n",
       "  14 │ UA         0.0402917    0.0402917    0.0402917\n",
       "  15 │ US        -0.452353    -0.452353    -0.452353\n",
       "  16 │ WN        -2.976       -2.976       -2.976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "\n",
    "hi = [XtX Xty; Xty' 1]\n",
    "df = DataFrame(beta = [\"beta0\",\"Tue\",\"Wed\",\"Thr\",\"Fri\",\"Sat\",\"Sun\",\"Dist\",\n",
    "                       \"DepDelay\", \"AS\", \"CO\", \"DL\", \"NW\", \"UA\", \"US\", \"WN\"], \n",
    "               LU = inv(XtX) * Xty,\n",
    "               Cholesky = cholesky(XtX) \\ Xty,\n",
    "               Sweep = sweep!(hi, 1:16)[1:16, end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4 Be proud of yourself\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analytics on data with 100 million observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1.4\n",
    "\n",
    "- Haven't done yet.\n",
    "- But it counts 0 point.\n",
    "- So I will add it to my CV later.\n",
    "- Indeed this is an excellent project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code\n",
    "\n",
    "Following code explores the data in 2003 and generates the design matrix and responses for that year. Feel free to use the code in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CodecBzip2, CSV, DataFrames, Distributions, LinearAlgebra, \n",
    "#Serialization, StatsModels, SweepOperator\n",
    "#ENV[\"COLUMNS\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay\n",
      "2003,1,29,3,1651,1655,1912,1913,UA,1017,N202UA,141,138,119,-1,-4,ORD,MSY,837,5,17,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,30,4,1654,1655,1910,1913,UA,1017,N311UA,136,138,108,-3,-1,ORD,MSY,837,2,26,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,31,5,1724,1655,1936,1913,UA,1017,N317UA,132,138,110,23,29,ORD,MSY,837,5,17,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,1,3,1033,1035,1625,1634,UA,1018,N409UA,232,239,215,-9,-2,OAK,ORD,1835,6,11,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,2,4,1053,1035,1726,1634,UA,1018,N496UA,273,239,214,52,18,OAK,ORD,1835,13,46,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,3,5,1031,1035,1640,1634,UA,1018,N412UA,249,239,223,6,-4,OAK,ORD,1835,13,13,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,4,6,1031,1035,1626,1634,UA,1018,N455UA,235,239,219,-8,-4,OAK,ORD,1835,5,11,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,5,7,1035,1035,1636,1634,UA,1018,N828UA,241,239,227,2,0,OAK,ORD,1835,5,9,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,6,1,1031,1035,1653,1634,UA,1018,N453UA,262,239,241,19,-4,OAK,ORD,1835,7,14,0,NA,0,NA,NA,NA,NA,NA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base.ProcessChain(Base.Process[Process(`\u001b[4mbunzip2\u001b[24m \u001b[4m-c\u001b[24m \u001b[4mflights/2003.csv.bz2\u001b[24m`, ProcessSignaled(13)), Process(`\u001b[4mhead\u001b[24m`, ProcessExited(0))], Base.DevNull(), Base.DevNull(), Base.DevNull())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 10 lines of 2003 data.\n",
    "run(pipeline(`bunzip2 -c flights/2003.csv.bz2`, `head`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488541"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many data points in 2003?\n",
    "open(\"flights/2003.csv.bz2\", \"r\") do io\n",
    "    countlines(Bzip2DecompressorStream(io))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. PageRank\n",
    "\n",
    "We are going to try different numerical methods learnt in class on the [Google PageRank problem](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 (5 pts) Recognize structure\n",
    "\n",
    "Let $\\mathbf{A} \\in \\{0,1\\}^{n \\times n}$ be the connectivity matrix of $n$ web pages with entries\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\ta_{ij}= \\begin{cases}\n",
    "\t1 & \\text{if page $i$ links to page $j$} \\\\\n",
    "\t0 & \\text{otherwise}\n",
    "\t\\end{cases}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "$r_i = \\sum_j a_{ij}$ is the out-degree of page $i$. That is $r_i$ is the number of links on page $i$. Imagine a random surfer exploring the space of $n$ pages according to the following rules.  \n",
    "\n",
    "- From a page $i$ with $r_i>0$\n",
    "    * with probability $p$, (s)he randomly chooses a link on page $i$ (uniformly) and follows that link to the next page  \n",
    "    * with probability $1-p$, (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "- From a page $i$ with $r_i=0$ (a dangling page), (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "    \n",
    "The process defines a Markov chain on the space of $n$ pages. Write the transition matrix $\\mathbf{P}$ of the Markov chain as a sparse matrix plus rank 1 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2.1\n",
    "\n",
    "The transition matrix $\\mathbf{P}$ can be written as\n",
    "\\begin{align}\n",
    "\\mathbf{P}&=p\\times\\text{Diag}(\\mathbf{A1})^{-1}\\mathbf{A} + (\\mathbf{1}-p\\mathbb{1}_{\\{\\mathbf{A1}>\\mathbf{0}\\}})\\odot\\frac{\\mathbf{11}^T}{n}\n",
    "\\end{align}\n",
    "where \n",
    "\n",
    "- $\\mathbf{A}$ is the **SPARSE** connectivity matrix.\n",
    "- $\\mathbf{1}$ is a $n\\times 1$ vector with all ones.\n",
    "- $\\text{Diag}(\\mathbf{A1})^{-1}$ is a diagonal matrix with elements $\\frac{1}{r_i}=\\frac{1}{\\sum_{j=1}^na_{ij}}$.\n",
    "- $\\mathbb{1}_{\\{\\mathbf{A1}>\\mathbf{0}\\}}$ is the indicator vector such that if $r_i=0$, then the element equals 0.\n",
    "- $\\odot$ is the Hadamard product.\n",
    "\n",
    "If $r_i=\\sum_{j=1}a_{ij}=0$, then set the inverse equal to 0 as well.\n",
    "\n",
    "Denote $\\mathbf{W}=\\text{Diag}(\\mathbf{A1})^{-1}\\mathbf{A}$ and $\\mathbf{c}=\\frac{1}{n}\\left(\\mathbf{1}-p\\mathbb{1}_{\\{\\mathbf{A1}>\\mathbf{0}\\}}\\right)\\odot\\mathbf{1}$, then the transition matrix is\n",
    "\\begin{align}\n",
    "\\mathbf{P}&=p\\mathbf{W}+\\mathbf{c}\\mathbf{1}^T\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{W}$ is sparse and $\\mathbf{c}\\mathbf{1}^T$ is of rank one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Relate to numerical linear algebra\n",
    "\n",
    "According to standard Markov chain theory, the (random) position of the surfer converges to the stationary distribution $\\mathbf{x} = (x_1,\\ldots,x_n)^T$ of the Markov chain. $x_i$ has the natural interpretation of the proportion of times the surfer visits page $i$ in the long run. Therefore $\\mathbf{x}$ serves as page ranks: a higher $x_i$ means page $i$ is more visited. It is well-known that $\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. That is $\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$. Therefore $\\mathbf{x}$ can be solved as an **eigen-problem**. It can also be cast as **solving a linear system**. Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient. We can replace the first equation by the $\\sum_{i=1}^n x_i = 1$.\n",
    "\n",
    "Hint: For iterative solvers, we don't need to replace the 1st equation. We can use the matrix $\\mathbf{I} - \\mathbf{P}^T$ directly if we start with a vector with all positive entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2.2\n",
    "\n",
    "To show proof $\\mathbf{I-P^T}$ is rank deficient, it is enough to show that there exists a unique nonnegative solution $\\mathbf{x}$ to\n",
    "\n",
    "$$\\mathbf{x}^T=\\mathbf{x}^T\\mathbf{P}$$\n",
    "\n",
    "and $\\mathbf{1}^T\\mathbf{x}<\\infty$. The reason is: $x=\\mathbf{0}$ is always a solution to $\\mathbf{x}^T=\\mathbf{x}^T\\mathbf{P}$ and full rank property of $\\mathbf{I-P^T}$ implies that $\\mathbf{0}$ is the **ONLY** solution, which is a contradiction to the statement that there exists another nonnegative solution.\n",
    "\n",
    "Here I quote a theorem from Biostat 270:\n",
    "\n",
    "**Theorem** ( Biostat 270, modified ) : Let $\\{X_n:n\\ge 0\\}$ be a Markov chain with state space $\\left(\\mathbb{S},\\mathcal{B}(\\mathbb{S})\\right)$ where $\\mathbb{S}$ is countable. Also, let $\\mathbf{P}$ be the transition matrix (or transition kernel) associated with the chain.\n",
    "\n",
    "Assume the following:\n",
    "- $\\{X_n:n\\ge 0\\}$ is recurrent.\n",
    "- $\\mathbf{P}$ is irreducible.\n",
    "- $0\\in\\mathbb{S}$ is a fixed state.\n",
    "Then the linear system\n",
    "$$\\mathbf{x}^T=\\mathbf{x}^T\\mathbf{P}$$\n",
    "has a **UNIQUE** nonnegative solution satisfying $x_0=1$. In the special case where $\\mathbb{S}$ is finite, we have\n",
    "$$\\mathbf{x}^T\\mathbf{1}<\\infty$$\n",
    "which means the solution vector $\\mathbf{x}$ can be re-scaled to a probability vector s.t.\n",
    "$$\\mathbf{x}^T\\mathbf{1}=\\mathbf{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 (10 pts) Explore data\n",
    "\n",
    "Obtain the connectivity matrix `A` from the `SNAP/web-Google` data in the MatrixDepot package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include group.jl for user defined matrix generators\n",
      "verify download of index files...\n",
      "reading database\n",
      "adding metadata...\n",
      "adding svd data...\n",
      "writing database\n",
      "used remote sites are sparse.tamu.edu with MAT index and math.nist.gov with HTML index\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{SNAP/web-Google}\n",
       "\\subsubparagraph{MatrixMarket matrix coordinate pattern general}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{itemize}\n",
       "\\item UF Sparse Matrix Collection, Tim Davis\n",
       "\n",
       "\n",
       "\\item http://www.cise.ufl.edu/research/sparse/matrices/SNAP/web-Google\n",
       "\n",
       "\n",
       "\\item name: SNAP/web-Google\n",
       "\n",
       "\n",
       "\\item [Web graph from Google]\n",
       "\n",
       "\n",
       "\\item id: 2301\n",
       "\n",
       "\n",
       "\\item date: 2002\n",
       "\n",
       "\n",
       "\\item author: Google\n",
       "\n",
       "\n",
       "\\item ed: J. Leskovec\n",
       "\n",
       "\n",
       "\\item fields: name title A id date author ed kind notes\n",
       "\n",
       "\n",
       "\\item kind: directed graph\n",
       "\n",
       "\\end{itemize}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{itemize}\n",
       "\\item notes:\n",
       "\n",
       "\n",
       "\\item Networks from SNAP (Stanford Network Analysis Platform) Network Data Sets,     \n",
       "\n",
       "\n",
       "\\item Jure Leskovec http://snap.stanford.edu/data/index.html                         \n",
       "\n",
       "\n",
       "\\item email jure at cs.stanford.edu                                                  \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Google web graph                                                               \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Dataset information                                                            \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Nodes represent web pages and directed edges represent hyperlinks between them.\n",
       "\n",
       "\n",
       "\\item The data was released in 2002 by Google as a part of Google Programming        \n",
       "\n",
       "\n",
       "\\item Contest.                                                                       \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Dataset statistics                                                             \n",
       "\n",
       "\n",
       "\\item Nodes   875713                                                                 \n",
       "\n",
       "\n",
       "\\item Edges   5105039                                                                \n",
       "\n",
       "\n",
       "\\item Nodes in largest WCC    855802 (0.977)                                         \n",
       "\n",
       "\n",
       "\\item Edges in largest WCC    5066842 (0.993)                                        \n",
       "\n",
       "\n",
       "\\item Nodes in largest SCC    434818 (0.497)                                         \n",
       "\n",
       "\n",
       "\\item Edges in largest SCC    3419124 (0.670)                                        \n",
       "\n",
       "\n",
       "\\item Average clustering coefficient  0.6047                                         \n",
       "\n",
       "\n",
       "\\item Number of triangles     13391903                                               \n",
       "\n",
       "\n",
       "\\item Fraction of closed triangles    0.05523                                        \n",
       "\n",
       "\n",
       "\\item Diameter (longest shortest path)    22                                         \n",
       "\n",
       "\n",
       "\\item 90-percentile effective diameter    8.1                                        \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Source (citation)                                                              \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney. Community Structure in Large    \n",
       "\n",
       "\n",
       "\\item Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters.\n",
       "\n",
       "\n",
       "\\item arXiv.org:0810.1355, 2008.                                                     \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Google programming contest, 2002                                               \n",
       "\n",
       "\n",
       "\\item http://www.google.com/programming-contest/                                     \n",
       "\n",
       "\n",
       "\\item \n",
       "\\item Files                                                                          \n",
       "\n",
       "\n",
       "\\item File    Description                                                            \n",
       "\n",
       "\n",
       "\\item web-Google.txt.gz   Webgraph from the Google programming contest, 2002         \n",
       "\n",
       "\\end{itemize}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "916428 916428 5105039\n",
       "\n"
      ],
      "text/markdown": [
       "# SNAP/web-Google\n",
       "\n",
       "###### MatrixMarket matrix coordinate pattern general\n",
       "\n",
       "---\n",
       "\n",
       "  * UF Sparse Matrix Collection, Tim Davis\n",
       "  * http://www.cise.ufl.edu/research/sparse/matrices/SNAP/web-Google\n",
       "  * name: SNAP/web-Google\n",
       "  * [Web graph from Google]\n",
       "  * id: 2301\n",
       "  * date: 2002\n",
       "  * author: Google\n",
       "  * ed: J. Leskovec\n",
       "  * fields: name title A id date author ed kind notes\n",
       "  * kind: directed graph\n",
       "\n",
       "---\n",
       "\n",
       "  * notes:\n",
       "  * Networks from SNAP (Stanford Network Analysis Platform) Network Data Sets,\n",
       "  * Jure Leskovec http://snap.stanford.edu/data/index.html\n",
       "  * email jure at cs.stanford.edu\n",
       "  * \n",
       "  * Google web graph\n",
       "  * \n",
       "  * Dataset information\n",
       "  * \n",
       "  * Nodes represent web pages and directed edges represent hyperlinks between them.\n",
       "  * The data was released in 2002 by Google as a part of Google Programming\n",
       "  * Contest.\n",
       "  * \n",
       "  * Dataset statistics\n",
       "  * Nodes   875713\n",
       "  * Edges   5105039\n",
       "  * Nodes in largest WCC    855802 (0.977)\n",
       "  * Edges in largest WCC    5066842 (0.993)\n",
       "  * Nodes in largest SCC    434818 (0.497)\n",
       "  * Edges in largest SCC    3419124 (0.670)\n",
       "  * Average clustering coefficient  0.6047\n",
       "  * Number of triangles     13391903\n",
       "  * Fraction of closed triangles    0.05523\n",
       "  * Diameter (longest shortest path)    22\n",
       "  * 90-percentile effective diameter    8.1\n",
       "  * \n",
       "  * Source (citation)\n",
       "  * \n",
       "  * J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney. Community Structure in Large\n",
       "  * Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters.\n",
       "  * arXiv.org:0810.1355, 2008.\n",
       "  * \n",
       "  * Google programming contest, 2002\n",
       "  * http://www.google.com/programming-contest/\n",
       "  * \n",
       "  * Files\n",
       "  * File    Description\n",
       "  * web-Google.txt.gz   Webgraph from the Google programming contest, 2002\n",
       "\n",
       "---\n",
       "\n",
       "916428 916428 5105039\n"
      ],
      "text/plain": [
       "\u001b[1m  SNAP/web-Google\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[1m  MatrixMarket matrix coordinate pattern general\u001b[22m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "    •  UF Sparse Matrix Collection, Tim Davis\n",
       "\n",
       "    •  http://www.cise.ufl.edu/research/sparse/matrices/SNAP/web-Google\n",
       "\n",
       "    •  name: SNAP/web-Google\n",
       "\n",
       "    •  [Web graph from Google]\n",
       "\n",
       "    •  id: 2301\n",
       "\n",
       "    •  date: 2002\n",
       "\n",
       "    •  author: Google\n",
       "\n",
       "    •  ed: J. Leskovec\n",
       "\n",
       "    •  fields: name title A id date author ed kind notes\n",
       "\n",
       "    •  kind: directed graph\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "    •  notes:\n",
       "\n",
       "    •  Networks from SNAP (Stanford Network Analysis Platform) Network Data Sets,\n",
       "\n",
       "    •  Jure Leskovec http://snap.stanford.edu/data/index.html\n",
       "\n",
       "    •  email jure at cs.stanford.edu\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Google web graph\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Dataset information\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Nodes represent web pages and directed edges represent hyperlinks between them.\n",
       "\n",
       "    •  The data was released in 2002 by Google as a part of Google Programming\n",
       "\n",
       "    •  Contest.\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Dataset statistics\n",
       "\n",
       "    •  Nodes 875713\n",
       "\n",
       "    •  Edges 5105039\n",
       "\n",
       "    •  Nodes in largest WCC 855802 (0.977)\n",
       "\n",
       "    •  Edges in largest WCC 5066842 (0.993)\n",
       "\n",
       "    •  Nodes in largest SCC 434818 (0.497)\n",
       "\n",
       "    •  Edges in largest SCC 3419124 (0.670)\n",
       "\n",
       "    •  Average clustering coefficient 0.6047\n",
       "\n",
       "    •  Number of triangles 13391903\n",
       "\n",
       "    •  Fraction of closed triangles 0.05523\n",
       "\n",
       "    •  Diameter (longest shortest path) 22\n",
       "\n",
       "    •  90-percentile effective diameter 8.1\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Source (citation)\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney. Community Structure in Large\n",
       "\n",
       "    •  Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters.\n",
       "\n",
       "    •  arXiv.org:0810.1355, 2008.\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Google programming contest, 2002\n",
       "\n",
       "    •  http://www.google.com/programming-contest/\n",
       "\n",
       "    •  \n",
       "\n",
       "    •  Files\n",
       "\n",
       "    •  File Description\n",
       "\n",
       "    •  web-Google.txt.gz Webgraph from the Google programming contest, 2002\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "  916428 916428 5105039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MatrixDepot\n",
    "\n",
    "md = mdopen(\"SNAP/web-Google\")\n",
    "# display documentation for the SNAP/web-Google data\n",
    "mdinfo(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916428×916428 SparseArrays.SparseMatrixCSC{Bool, Int64} with 5105039 stored entries:\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿\n",
       "⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connectivity matrix\n",
    "A = md.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute summary statistics:\n",
    "* How much memory does `A` take? If converted to a `Matrix{Float64}` (don't do it!), how much memory will it take?  \n",
    "* number of web pages\n",
    "* number of edges (web links). \n",
    "* number of dangling nodes (pages with no out links)\n",
    "* histogram of in-degrees  \n",
    "* list the top 20 pages with the largest in-degrees?  \n",
    "* histogram of out-degrees\n",
    "* which the top 20 pages with the largest out-degrees?\n",
    "* visualize the sparsity pattern of $\\mathbf{A}$ or a submatrix of $\\mathbf{A}$ say `A[1:10000, 1:10000]`. \n",
    "\n",
    "**Hint**: For plots, you can use the [UnicodePlots.jl](https://github.com/Evizero/UnicodePlots.jl) package (`spy`, `histogram`, etc), which is fast for large data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol2.3\n",
    "\n",
    "- How much memory does `A` take?\n",
    "\n",
    "**Sol**: According to the table returned by `varinfo()`, it takes 50.809 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{tabular}\n",
       "{l | r | l}\n",
       "name & size & summary \\\\\n",
       "\\hline\n",
       "A & 50.809 MiB & 916428×916428 SparseArrays.SparseMatrixCSC\\{Bool, Int64\\} \\\\\n",
       "Base &  & Module \\\\\n",
       "Core &  & Module \\\\\n",
       "Main &  & Module \\\\\n",
       "XtX & 2.039 KiB & 16×16 Matrix\\{Float64\\} \\\\\n",
       "Xty & 168 bytes & 16-element Vector\\{Float64\\} \\\\\n",
       "airlines & 184 bytes & 8-element Vector\\{String\\} \\\\\n",
       "df & 1.454 KiB & 16×4 DataFrame \\\\\n",
       "files & 656 bytes & 22-element Vector\\{String\\} \\\\\n",
       "hi & 2.297 KiB & 17×17 Matrix\\{Float64\\} \\\\\n",
       "md & 50.811 MiB & MatrixDepot.MatrixDescriptor\\{MatrixDepot.RemoteMatrixData\\{MatrixDepot.SSRemoteType\\}\\} \\\\\n",
       "obs\\_count & 8 bytes & Int64 \\\\\n",
       "total\\_size & 8 bytes & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "| name       |       size | summary                                                                              |\n",
       "|:---------- | ----------:|:------------------------------------------------------------------------------------ |\n",
       "| A          | 50.809 MiB | 916428×916428 SparseArrays.SparseMatrixCSC{Bool, Int64}                              |\n",
       "| Base       |            | Module                                                                               |\n",
       "| Core       |            | Module                                                                               |\n",
       "| Main       |            | Module                                                                               |\n",
       "| XtX        |  2.039 KiB | 16×16 Matrix{Float64}                                                                |\n",
       "| Xty        |  168 bytes | 16-element Vector{Float64}                                                           |\n",
       "| airlines   |  184 bytes | 8-element Vector{String}                                                             |\n",
       "| df         |  1.454 KiB | 16×4 DataFrame                                                                       |\n",
       "| files      |  656 bytes | 22-element Vector{String}                                                            |\n",
       "| hi         |  2.297 KiB | 17×17 Matrix{Float64}                                                                |\n",
       "| md         | 50.811 MiB | MatrixDepot.MatrixDescriptor{MatrixDepot.RemoteMatrixData{MatrixDepot.SSRemoteType}} |\n",
       "| obs_count  |    8 bytes | Int64                                                                                |\n",
       "| total_size |    8 bytes | Int64                                                                                |\n"
      ],
      "text/plain": [
       "  name             size summary                                                                             \n",
       "  –––––––––– –––––––––– ––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
       "  A          50.809 MiB 916428×916428 SparseArrays.SparseMatrixCSC{Bool, Int64}                             \n",
       "  Base                  Module                                                                              \n",
       "  Core                  Module                                                                              \n",
       "  Main                  Module                                                                              \n",
       "  XtX         2.039 KiB 16×16 Matrix{Float64}                                                               \n",
       "  Xty         168 bytes 16-element Vector{Float64}                                                          \n",
       "  airlines    184 bytes 8-element Vector{String}                                                            \n",
       "  df          1.454 KiB 16×4 DataFrame                                                                      \n",
       "  files       656 bytes 22-element Vector{String}                                                           \n",
       "  hi          2.297 KiB 17×17 Matrix{Float64}                                                               \n",
       "  md         50.811 MiB MatrixDepot.MatrixDescriptor{MatrixDepot.RemoteMatrixData{MatrixDepot.SSRemoteType}}\n",
       "  obs_count     8 bytes Int64                                                                               \n",
       "  total_size    8 bytes Int64                                                                               "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If converted to a `Matrix{Float64}` (don't do it!), how much memory will it take? \n",
    "\n",
    "**Sol**: All elements will be converted from `Bool` to `Float64` and all zeros will be filled, so it will take (approximately)\n",
    "\n",
    "$$m=8\\times col(A)\\times row(A)\\ /\\ 1024\\ (KB)$$\n",
    "\n",
    "After some calculation, \n",
    "$$m=8\\times 916428 \\times 916428\\ /\\ 1024\\approx 6.56\\times 10^{9} KB$$\n",
    "or $$6.41\\times 10^{3}\\ GB$$ \n",
    "equivalently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of web pages\n",
    "\n",
    "**Sol**: 916428."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of edges (web links)\n",
    "\n",
    "**Sol**: Indeed this should be 5105039 edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of dangling nodes (pages with no out links)\n",
    "\n",
    "**Sol**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176974"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SparseArrays\n",
    "\n",
    "B = findnz(A)\n",
    "\n",
    "916428 - length(unique(B[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- histogram of in-degrees where $in\\_degrees=\\sum_ia_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m                    ┌                                        ┐\u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m   0.0\u001b[90m, \u001b[0m 200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 713286 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 200.0\u001b[90m, \u001b[0m 400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 812                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 400.0\u001b[90m, \u001b[0m 600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 203                       \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 600.0\u001b[90m, \u001b[0m 800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 80                           \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 800.0\u001b[90m, \u001b[0m1000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 30                             \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m1000.0\u001b[90m, \u001b[0m1200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇\u001b[39m\u001b[0m 19                              \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m1200.0\u001b[90m, \u001b[0m1400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 12                               \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m1400.0\u001b[90m, \u001b[0m1600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 6                                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m1600.0\u001b[90m, \u001b[0m1800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 6                                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m1800.0\u001b[90m, \u001b[0m2000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 9                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m2000.0\u001b[90m, \u001b[0m2200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 8                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m2200.0\u001b[90m, \u001b[0m2400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇\u001b[39m\u001b[0m 4                                   \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m2400.0\u001b[90m, \u001b[0m2600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 7                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m2600.0\u001b[90m, \u001b[0m2800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 11                               \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m2800.0\u001b[90m, \u001b[0m3000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 6                                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m3000.0\u001b[90m, \u001b[0m3200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 9                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m3200.0\u001b[90m, \u001b[0m3400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 8                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m3400.0\u001b[90m, \u001b[0m3600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇\u001b[39m\u001b[0m 3                                   \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m3600.0\u001b[90m, \u001b[0m3800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 1                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m3800.0\u001b[90m, \u001b[0m4000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 7                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m4000.0\u001b[90m, \u001b[0m4200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 5                                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m4200.0\u001b[90m, \u001b[0m4400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇\u001b[39m\u001b[0m 3                                   \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m4400.0\u001b[90m, \u001b[0m4600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 2                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m4600.0\u001b[90m, \u001b[0m4800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 2                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m4800.0\u001b[90m, \u001b[0m5000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 1                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m5000.0\u001b[90m, \u001b[0m5200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 2                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m5200.0\u001b[90m, \u001b[0m5400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 2                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m5400.0\u001b[90m, \u001b[0m5600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m5600.0\u001b[90m, \u001b[0m5800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m5800.0\u001b[90m, \u001b[0m6000.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m6000.0\u001b[90m, \u001b[0m6200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m6200.0\u001b[90m, \u001b[0m6400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 1                                      \u001b[90m \u001b[39m \n",
       "\u001b[90m                    └                                        ┘\u001b[39m \n",
       "\u001b[0m                                Frequency [log10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using UnicodePlots\n",
    "using StatsBase\n",
    "\n",
    "in_degrees = collect(values(countmap(B[2]))) \n",
    "histogram(in_degrees, nbins = 35, closed = :left, xscale=log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list the top 20 pages with the largest in-degrees?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{Int64, Int64} with 714545 entries:\n",
       "  537040 => 6326\n",
       "  597622 => 5354\n",
       "  504141 => 5271\n",
       "  751385 => 5182\n",
       "  32164  => 5097\n",
       "  885606 => 4847\n",
       "  163076 => 4731\n",
       "  819224 => 4620\n",
       "  605857 => 4550\n",
       "  828964 => 4484\n",
       "  551830 => 4220\n",
       "  41910  => 4219\n",
       "  558792 => 4206\n",
       "  459075 => 4187\n",
       "  407611 => 4180\n",
       "  213433 => 4084\n",
       "  765335 => 4015\n",
       "  384667 => 4010\n",
       "  173977 => 3988\n",
       "  687326 => 3956\n",
       "  425771 => 3940\n",
       "  396322 => 3913\n",
       "  486981 => 3908\n",
       "  182122 => 3872\n",
       "  908352 => 3810\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(countmap(B[2]), byvalue=true, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- histogram of out-degrees\n",
    "\n",
    "$out\\_degrees=\\sum_{j=1}^na_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m                  ┌                                        ┐\u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m  0.0\u001b[90m, \u001b[0m 20.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 714824 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 20.0\u001b[90m, \u001b[0m 40.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 22628          \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 40.0\u001b[90m, \u001b[0m 60.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 1329                  \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 60.0\u001b[90m, \u001b[0m 80.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 371                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m 80.0\u001b[90m, \u001b[0m100.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 124                         \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m100.0\u001b[90m, \u001b[0m120.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 86                          \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m120.0\u001b[90m, \u001b[0m140.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 29                             \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m140.0\u001b[90m, \u001b[0m160.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 15                               \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m160.0\u001b[90m, \u001b[0m180.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 15                               \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m180.0\u001b[90m, \u001b[0m200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 8                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m200.0\u001b[90m, \u001b[0m220.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 7                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m220.0\u001b[90m, \u001b[0m240.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇\u001b[39m\u001b[0m 3                                   \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m240.0\u001b[90m, \u001b[0m260.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇\u001b[39m\u001b[0m 8                                 \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m260.0\u001b[90m, \u001b[0m280.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇\u001b[39m\u001b[0m 3                                   \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m280.0\u001b[90m, \u001b[0m300.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m300.0\u001b[90m, \u001b[0m320.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m320.0\u001b[90m, \u001b[0m340.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 1                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m340.0\u001b[90m, \u001b[0m360.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m360.0\u001b[90m, \u001b[0m380.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 2                                    \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m380.0\u001b[90m, \u001b[0m400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m400.0\u001b[90m, \u001b[0m420.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m420.0\u001b[90m, \u001b[0m440.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 0                                      \u001b[90m \u001b[39m \n",
       "   \u001b[0m\u001b[90m[\u001b[0m440.0\u001b[90m, \u001b[0m460.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[0m 1                                      \u001b[90m \u001b[39m \n",
       "\u001b[90m                  └                                        ┘\u001b[39m \n",
       "\u001b[0m                              Frequency [log10]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_degrees = collect(values(countmap(B[1]))) \n",
    "histogram(out_degrees, nbins = 35, closed = :left, xscale=log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which the top 20 pages with the largest out-degrees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{Int64, Int64} with 739454 entries:\n",
       "  506743 => 456\n",
       "  203749 => 372\n",
       "  305230 => 372\n",
       "  768092 => 330\n",
       "  808644 => 277\n",
       "  412411 => 268\n",
       "  600480 => 265\n",
       "  376429 => 258\n",
       "  156951 => 257\n",
       "  885729 => 256\n",
       "  667585 => 253\n",
       "  685696 => 248\n",
       "  282141 => 247\n",
       "  598189 => 245\n",
       "  579315 => 244\n",
       "  411594 => 231\n",
       "  321092 => 229\n",
       "  838279 => 225\n",
       "  302734 => 216\n",
       "  915274 => 213\n",
       "  285815 => 210\n",
       "  41298  => 206\n",
       "  432907 => 206\n",
       "  440090 => 203\n",
       "  674718 => 200\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(countmap(B[1]), byvalue=true, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize the sparsity pattern of $\\mathbf{A}$ or a submatrix of $\\mathbf{A}$ say `A[1:10000, 1:10000]`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m                      Sparsity Pattern\u001b[22m\n",
       "\u001b[90m         ┌──────────────────────────────────────────┐\u001b[39m    \n",
       "       \u001b[90m1\u001b[39m\u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⢂\u001b[39m\u001b[31m⡂\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠔\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m \u001b[31m> 0\u001b[39m\n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⡂\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⡔\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠒\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m \u001b[34m< 0\u001b[39m\n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⢐\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠢\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠋\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠰\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⠆\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⡠\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⡀\u001b[39m\u001b[31m⠐\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⢠\u001b[39m\u001b[0m⠀\u001b[31m⠢\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⡁\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡄\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠪\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⡉\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⠐\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⠐\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⡠\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠚\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠆\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠂\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⡄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠒\u001b[39m\u001b[0m⠀\u001b[31m⢄\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⢂\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠣\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⢠\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⢠\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡈\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⡦\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠅\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠨\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠨\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⢐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠉\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠨\u001b[39m\u001b[0m⠀\u001b[31m⠋\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡑\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠐\u001b[39m\u001b[31m⠼\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡈\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠡\u001b[39m\u001b[31m⠄\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⡁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠤\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⡂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⢈\u001b[39m\u001b[0m⠀\u001b[31m⢔\u001b[39m\u001b[31m⡊\u001b[39m\u001b[31m⣨\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠤\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠘\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⢘\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⢐\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⢠\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⡊\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⠢\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⡀\u001b[39m\u001b[31m⡑\u001b[39m\u001b[0m⠀\u001b[31m⡐\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⡂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠰\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⢠\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠃\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠅\u001b[39m\u001b[0m⠀\u001b[31m⡁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢁\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⡀\u001b[39m\u001b[31m⡐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠔\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⢉\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠊\u001b[39m\u001b[31m⢈\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠅\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⢠\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢰\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠂\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⡂\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠌\u001b[39m\u001b[31m⠅\u001b[39m\u001b[31m⣀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠲\u001b[39m\u001b[31m⢂\u001b[39m\u001b[0m⠀\u001b[31m⠰\u001b[39m\u001b[31m⡄\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⠬\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠙\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡄\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠸\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠡\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⢉\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡐\u001b[39m\u001b[31m⠑\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[31m⠠\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[31m⠄\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢰\u001b[39m\u001b[31m⡄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠉\u001b[39m\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⠠\u001b[39m\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[31m⡁\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⡈\u001b[39m\u001b[31m⠆\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⢀\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠤\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠠\u001b[39m\u001b[90m│\u001b[39m    \n",
       "        \u001b[90m │\u001b[39m\u001b[0m⠀\u001b[31m⠅\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⠂\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[31m⡠\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠄\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡀\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[31m⡢\u001b[39m\u001b[0m⠀\u001b[31m⠙\u001b[39m\u001b[0m⠀\u001b[31m⠇\u001b[39m\u001b[0m⠀\u001b[31m⢂\u001b[39m\u001b[0m⠀\u001b[31m⣠\u001b[39m\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[0m⠀\u001b[31m⠥\u001b[39m\u001b[31m⠄\u001b[39m\u001b[31m⢁\u001b[39m\u001b[31m⡀\u001b[39m\u001b[31m⡀\u001b[39m\u001b[90m│\u001b[39m    \n",
       "   \u001b[90m10000\u001b[39m\u001b[90m │\u001b[39m\u001b[31m⠘\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠃\u001b[39m\u001b[31m⡁\u001b[39m\u001b[31m⠨\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠐\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⠄\u001b[39m\u001b[0m⠀\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠂\u001b[39m\u001b[31m⠁\u001b[39m\u001b[31m⢈\u001b[39m\u001b[31m⠁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⡁\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⢀\u001b[39m\u001b[31m⢰\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[31m⠈\u001b[39m\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[0m⠀\u001b[31m⡂\u001b[39m\u001b[0m⠀\u001b[90m│\u001b[39m    \n",
       "\u001b[90m         └──────────────────────────────────────────┘\u001b[39m    \n",
       "\u001b[90m         1\u001b[39m\u001b[90m                    \u001b[39m\u001b[90m                  10000\u001b[39m\n",
       "\u001b[0m                          nz = 600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy(A[1:10000, 1:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.4 (5 pts) Dense linear algebra? \n",
    "\n",
    "Consider the following methods to obtain the page ranks of the `SNAP/web-Google` data. \n",
    "\n",
    "1. A dense linear system solver such as LU decomposition.  \n",
    "2. A dense eigen-solver for asymmetric matrix.  \n",
    "\n",
    "For the LU approach, estimate (1) the memory usage and (2) how long it will take assuming that the LAPACK functions can achieve the theoretical throughput of your computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2.4\n",
    "\n",
    "First, let me do a benchmark testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.64 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     14.356 ms (0.00% GC)\n",
       "  median time:      17.701 ms (0.00% GC)\n",
       "  mean time:        18.965 ms (0.30% GC)\n",
       "  maximum time:     103.406 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          264\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "function test_lu(Σ::Matrix)\n",
    "   lu(Σ)\n",
    "end\n",
    "\n",
    "Σ = randn(1000, 1000)\n",
    "\n",
    "@benchmark test_lu($Σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) A quote from the GELU lecture: \"To solve  𝐀𝐱=𝐛  via LU, we need a total of $\\frac{2}{3}n^3+2n^2$ flops.\" Besides, the whole LU algorithm is done in place and we need a matrix to store $\\mathbf{L}$ or $\\mathbf{M}_i,i=1,\\cdots,n-1$ and get $\\mathbf{U}$ automatically.\n",
    "\n",
    "Thus, to estimate the memory usage, we need approximately\n",
    "$$2\\times8\\times916428^2 / 1024^3 = 12514.595\\ GB$$\n",
    "\n",
    "Besides, according to the results given by benchmark, \n",
    "$$7.64 / 1000^2 \\times 916428^2 / 1024 \\approx 6265.996\\ GB$$\n",
    "which means the benchmark function doesn't take the additional matrix into account.\n",
    "\n",
    "- (2) By the $O(n^3)$ result, it will take approximately\n",
    "$$18.981 / 1000^3 \\times 916428^3/1000/3600\\approx 4057.996\\ h$$\n",
    "to finish the LU decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.5 Iterative solvers\n",
    "\n",
    "Set the _teleportation_ parameter at $p = 0.85$. Consider the following methods for solving the PageRank problem. \n",
    "\n",
    "1. An iterative linear system solver such as GMRES. \n",
    "2. An iterative eigen-solver such as Arnoldi method.\n",
    "\n",
    "For iterative methods, we have many choices in Julia. See a list of existing Julia packages for linear solvers at this [page](https://jutho.github.io/KrylovKit.jl/stable/#Package-features-and-alternatives-1). The start-up code below uses the [KrylovKit.jl](https://github.com/Jutho/KrylovKit.jl) package. You can use other packages if you prefer. Make sure to utilize the special structure of $\\mathbf{P}$ (sparse + rank 1) to speed up the matrix-vector multiplication. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 (15 pts)\n",
    "\n",
    "Let's implement a type `PageRankImPt` that mimics the matrix $\\mathbf{M} = \\mathbf{I} - \\mathbf{P}^T$. For iterative methods, all we need to provide are methods for evaluating $\\mathbf{M} \\mathbf{v}$ and $\\mathbf{M}^T \\mathbf{v}$ for arbitrary vector $\\mathbf{v}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools, LinearAlgebra, SparseArrays, Revise\n",
    "\n",
    "# a type for the matrix M = I - P^T in PageRank problem\n",
    "struct PageRankImPt{TA <: Number, IA <: Integer, T <: AbstractFloat} <: AbstractMatrix{T}\n",
    "    A         :: SparseMatrixCSC{TA, IA} # adjacency matrix\n",
    "    telep     :: T\n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    n         :: IA # nrow and ncol of A\n",
    "    storage_n :: Matrix{IA} # an intermediate nx1 matrix\n",
    "    one       :: Vector{T} # a nx1 vector with elements corresponding to \\mathbf{c}\n",
    "    degree    :: Vector{T} # inverse of the degree vector\n",
    "    E         :: Diagonal{T} # Inverse of degree matrix\n",
    "    W         :: SparseMatrixCSC{T, IA} # normalized A times telep\n",
    "    Wt        :: Transpose{T, SparseMatrixCSC{T, IA}} # transpose of W\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function PageRankImPt(A::SparseMatrixCSC, telep::T) where T <: AbstractFloat\n",
    "    n = size(A, 1)\n",
    "    # TODO: initialize and pre-allocate arrays\n",
    "    \n",
    "    degree = Vector{T}(undef, n)\n",
    "    one = Vector{T}(undef, n)\n",
    "    \n",
    "    storage_n = sum(A, dims=2)\n",
    "    \n",
    "    # I am trying not to use for loop for simplicity\n",
    "    #for i in 1:n\n",
    "    #    if storage_n[i] > 0.0\n",
    "    #        degree[i] = telep / storage_n[i]\n",
    "    #        one[i] = (1 - telep) / n\n",
    "    #    elseif storage_n[i] == 0.0\n",
    "    #        degree[i] = 0.0\n",
    "    #        one[i] = 1 / n\n",
    "    #    end\n",
    "    #end\n",
    "    \n",
    "    one .= (1 .- (vec(storage_n) .> 0) .* telep) / n\n",
    "    E = Diagonal(replace(1 ./ vec(storage_n) .* telep, Inf=>0))\n",
    "\n",
    "    #E = Diagonal(degree)\n",
    "    W = convert(SparseMatrixCSC{Float64, Int64}, A)\n",
    "    mul!(W, E, A)\n",
    "    Wt = transpose(W)    \n",
    "    \n",
    "    PageRankImPt(A, telep, n, storage_n, one, degree, E, W, Wt)\n",
    "end\n",
    "\n",
    "LinearAlgebra.issymmetric(::PageRankImPt) = false\n",
    "Base.size(M::PageRankImPt) = size(M.A)\n",
    "# TODO: implement this function for evaluating M[i, j]\n",
    "Base.getindex(M::PageRankImPt, i, j) = M.telep\n",
    "\n",
    "# overwrite `out` by `(I - Pt) * v`\n",
    "function LinearAlgebra.mul!(\n",
    "        out :: Vector{T}, \n",
    "        M   :: PageRankImPt{<:Number, <:Integer, T}, \n",
    "        v   :: Vector{T}) where T <: AbstractFloat\n",
    "    # TODO: implement mul!(out, M, v)\n",
    "    #sleep(1e-2) # wait 10 ms as if your code takes 1ms\n",
    "    \n",
    "    M.degree .= dot(M.one, v)\n",
    "    mul!(out, M.Wt, v)\n",
    "    axpby!(1, M.degree, 1, out)\n",
    "    axpby!(1, v, -1, out)\n",
    "    \n",
    "    return out\n",
    "end\n",
    "\n",
    "# overwrite `out` by `(I - P) * v`\n",
    "function LinearAlgebra.mul!(\n",
    "        out :: Vector{T}, \n",
    "        Mt  :: Transpose{T, PageRankImPt{TA, IA, T}}, \n",
    "        v   :: Vector{T}) where {TA<:Number, IA<:Integer, T <: AbstractFloat}\n",
    "    M = Mt.parent\n",
    "    # TODO: implement mul!(out, transpose(M), v)\n",
    "    #sleep(1e-2) # wait 10 ms as if your code takes 1ms\n",
    "    \n",
    "    mul!(out, M.W, v)\n",
    "    axpby!(sum(v), M.one, 1, out)\n",
    "    axpy!(-1, v, out)\n",
    "    \n",
    "    out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check correctness. Note \n",
    "$$\n",
    "\\mathbf{M}^T \\mathbf{1} = \\mathbf{0}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{M} \\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "for stationary distribution $\\mathbf{x}$.\n",
    "\n",
    "Download the solution file `pgrksol.csv.gz`. **Do not put this file in your Git**. You will lose points if you do. You can add a line `pgrksol.csv.gz` to your `.gitignore` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916428-element Vector{Float64}:\n",
       " 3.3783428216975054e-5\n",
       " 2.0710155392568165e-6\n",
       " 3.663065984832893e-6\n",
       " 7.527510785028837e-7\n",
       " 8.63328599674051e-7\n",
       " 1.769418252415541e-6\n",
       " 2.431230382883396e-7\n",
       " 6.368417180141445e-7\n",
       " 4.744973703681939e-7\n",
       " 2.6895486110647536e-7\n",
       " 3.18574314847409e-6\n",
       " 7.375106374416742e-7\n",
       " 2.431230382883396e-7\n",
       " ⋮\n",
       " 1.1305006040148547e-6\n",
       " 4.874825281822915e-6\n",
       " 3.167946973112519e-6\n",
       " 9.72688040308568e-7\n",
       " 6.588614479285245e-7\n",
       " 7.737011774300648e-7\n",
       " 2.431230382883396e-7\n",
       " 1.6219204214797293e-6\n",
       " 3.912130060551738e-7\n",
       " 2.431230382883396e-7\n",
       " 7.296033831163157e-6\n",
       " 6.330939996912478e-7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CodecZlib, DelimitedFiles\n",
    "\n",
    "#isfile(\"pgrksol.csv.gz\") || download(\"https://raw.githubusercontent.com/ucla-biostat-257-2021spring/ucla-biostat-257-2021spring.github.io/master/hw/hw3/pgrksol.csv.gz\")\n",
    "xsol = open(\"pgrksol.csv.gz\", \"r\") do io\n",
    "    vec(readdlm(GzipDecompressorStream(io)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will lose all 35 points (Steps 1 and 2)** if the following statements throw AssertError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = PageRankImPt(A, 0.85)\n",
    "n = size(M, 1)\n",
    "\n",
    "@assert norm(transpose(M) * ones(n)) < 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert norm(M * xsol) < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 (20 pts)\n",
    "\n",
    "We want to benchmark the hot functions `mul!` to make sure they are efficient and allocate little memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     12.643 ms (0.00% GC)\n",
       "  median time:      13.184 ms (0.00% GC)\n",
       "  mean time:        13.260 ms (0.00% GC)\n",
       "  maximum time:     18.716 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          369\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = PageRankImPt(A, 0.85)\n",
    "n = size(M, 1)\n",
    "v, out = ones(n), zeros(n)\n",
    "bm_mv = @benchmark mul!($out, $M, $v) setup=(fill!(out, 0); fill!(v, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     12.196 ms (0.00% GC)\n",
       "  median time:      12.648 ms (0.00% GC)\n",
       "  mean time:        12.843 ms (0.00% GC)\n",
       "  maximum time:     22.754 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          380\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_mtv = @benchmark mul!($out, $(transpose(M)), $v) setup=(fill!(out, 0); fill!(v, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will lose 1 point for each 100 bytes memory allocation. So the points you will get is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_mv).memory / 100, 0, 10) + \n",
    "clamp(10 - median(bm_mtv).memory / 100, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: My median run times are 30-40 ms and memory allocations are 0 bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 (20 pts)\n",
    "\n",
    "Let's first try to solve the PageRank problem by the GMRES method for solving linear equations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(value = ([3.378342822189115e-5, 2.071015539248594e-6, 3.663065985237407e-6, 7.527510785603228e-7, 8.633285997161995e-7, 1.7694182527379288e-6, 2.431230382912353e-7, 6.368417180747728e-7, 4.7449737037503676e-7, 2.6895486110967837e-7  …  3.1679469739779265e-6, 9.726880410231945e-7, 6.58861447854298e-7, 7.737011774715262e-7, 2.431230382912353e-7, 1.6219204214247505e-6, 3.9121300606317777e-7, 2.431230382912353e-7, 7.29603383132553e-6, 6.330939996678948e-7], ConvergenceInfo: one converged value after 3 iterations and 72 applications of the linear map;\n",
       "norms of residuals are given by (7.821165996467032e-13,).\n",
       "), time = 7.384837084, bytes = 1010080681, gctime = 0.01416625, gcstats = Base.GC_Diff(1010080681, 137, 0, 79518, 5, 0, 14166250, 2, 0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using KrylovKit\n",
    "\n",
    "# normalize in-degrees to be the start point\n",
    "x0   = vec(sum(A, dims = 1)) .+ 1.0\n",
    "x0 ./= sum(x0)\n",
    "\n",
    "# right hand side\n",
    "b = zeros(n)\n",
    "\n",
    "# warm up (compilation)\n",
    "linsolve(M, b, x0, issymmetric = false, isposdef = false, maxiter = 1) \n",
    "# output is complex eigenvalue/eigenvector\n",
    "(x_gmres, info), time_gmres, = @timed linsolve(M, b, x0, issymmetric = false, isposdef = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correctness. **You will lose all 20 points if the following statement throws `AssertError`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert norm(x_gmres - xsol) < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMRES should be reasonably fast. The points you'll get is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(20 / time_gmres * 20, 0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: My runtime is about 7-8 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 (20 pts)\n",
    "\n",
    "Let's first try to solve the PageRank problem by the Arnoldi method for solving eigen problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(value = ([-0.6058148143729085, -0.5905363309090337], [[-0.0071881547641500934, -0.00020495885779635634, -0.0006883413970740808, -0.0001015578216536862, -0.00015738938945433284, -0.00022999469738552164, -3.835277242599948e-5, -8.370099222379294e-5, -7.465700224443492e-5, -4.270696397106171e-5  …  -0.00023242872484059983, -9.067577752256115e-5, -0.00013284774172213197, -0.0001500311627915099, -3.835277242599948e-5, -0.00026889238635563316, -7.300039900377995e-5, -3.835277242599948e-5, -0.0011127577375561232, -0.00010848327876937076], [-0.007221147622892764, 0.00014541132724083422, -0.0011993513749421244, 7.746296356657e-5, -0.00011117061116655749, 0.00012590975215432513, 1.9629331768727213e-6, 7.974146041031269e-5, 1.146285009173615e-5, 6.328350774432412e-7  …  0.0009308332347558533, -0.0002953087667275572, -8.258239043725489e-5, -4.6059115432044376e-5, 1.9629331768727213e-6, -9.370117511499672e-5, -1.4049824756195548e-6, 1.9629331768727213e-6, 5.037409919239072e-5, -2.4157753320742133e-5]], ConvergenceInfo: 2 converged values after 15 iterations and 198 applications of the linear map;\n",
       "norms of residuals are given by (1.3457122448153133e-13, 0.0).\n",
       "), time = 20.02228, bytes = 3346403960, gctime = 0.063720334, gcstats = Base.GC_Diff(3346403960, 455, 0, 163829, 113, 0, 63720334, 7, 0))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up (compilation)\n",
    "eigsolve(M, x0, 1, :SR, issymmetric = false, maxiter = 1)\n",
    "# output is complex eigenvalue/eigenvector\n",
    "(vals, vecs, info), time_arnoldi, = @timed eigsolve(M, x0, 1, :SR, issymmetric = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correctness. **You will lose all 20 points if the following statement throws `AssertError`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6058148143729085"
     ]
    }
   ],
   "source": [
    "#@assert abs(Real(vals[1])) < 1e-8\n",
    "print(abs(Real(vals[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015684295456147002"
     ]
    }
   ],
   "source": [
    "x_arnoldi   = abs.(Real.(vecs[1]))\n",
    "x_arnoldi ./= sum(x_arnoldi)\n",
    "#@assert norm(x_arnoldi - xsol) < 1e-8\n",
    "print(norm(x_arnoldi - xsol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arnoldi should be reasonably fast. The points you'll get is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.977744792301376"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(20 / time_arnoldi * 20, 0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: My runtime is about 11-12 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.6 (5 pts) Results\n",
    "\n",
    "List the top 20 pages you found and their corresponding PageRank score. Do they match the top 20 pages ranked according to in-degrees? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2.6\n",
    "\n",
    "- The results are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{Int64, Float64} with 916428 entries:\n",
       "  537040 => 0.00105074\n",
       "  597622 => 0.000889318\n",
       "  504141 => 0.000875534\n",
       "  751385 => 0.000860754\n",
       "  32164  => 0.000846638\n",
       "  885606 => 0.000805119\n",
       "  163076 => 0.000785855\n",
       "  819224 => 0.000767421\n",
       "  605857 => 0.000755796\n",
       "  828964 => 0.000744835\n",
       "  551830 => 0.000700992\n",
       "  41910  => 0.000700826\n",
       "  558792 => 0.000698667\n",
       "  459075 => 0.000695512\n",
       "  407611 => 0.000694349\n",
       "  213433 => 0.000678406\n",
       "  765335 => 0.000666947\n",
       "  384667 => 0.000666117\n",
       "  173977 => 0.000662463\n",
       "  687326 => 0.000657149\n",
       "  425771 => 0.000654492\n",
       "  396322 => 0.000650008\n",
       "  486981 => 0.000649177\n",
       "  182122 => 0.000643199\n",
       "  908352 => 0.000632902\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Vector(1:916428)\n",
    "score_vec= Dict(index .=> x0)\n",
    "sort(score_vec, byvalue=true, rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{Int64, Int64} with 714545 entries:\n",
       "  537040 => 6326\n",
       "  597622 => 5354\n",
       "  504141 => 5271\n",
       "  751385 => 5182\n",
       "  32164  => 5097\n",
       "  885606 => 4847\n",
       "  163076 => 4731\n",
       "  819224 => 4620\n",
       "  605857 => 4550\n",
       "  828964 => 4484\n",
       "  551830 => 4220\n",
       "  41910  => 4219\n",
       "  558792 => 4206\n",
       "  459075 => 4187\n",
       "  407611 => 4180\n",
       "  213433 => 4084\n",
       "  765335 => 4015\n",
       "  384667 => 4010\n",
       "  173977 => 3988\n",
       "  687326 => 3956\n",
       "  425771 => 3940\n",
       "  396322 => 3913\n",
       "  486981 => 3908\n",
       "  182122 => 3872\n",
       "  908352 => 3810\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(countmap(B[2]), byvalue=true, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.7 Be proud of yourself\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analysis on a network of one million nodes."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
